{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1GH7bR6ZoFHqfUnAl83I3i4wfYC6Rgwcv","authorship_tag":"ABX9TyONgd4WgmqvgFBhThlpOuS0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"pk-BHnXB11DO","executionInfo":{"status":"ok","timestamp":1761470941646,"user_tz":-480,"elapsed":855,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"}}},"outputs":[],"source":["import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","import geopandas as gpd"]},{"cell_type":"code","source":["def read_csv(csv_dir):\n","\n","  print(f\"\\n{'='*70}\")\n","  print(\"READ AND PROCESS CSV FILES\")\n","  print(f\"{'='*70}\")\n","\n","  # Read csv files\n","  csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n","  print(f\"Found {len(csv_files)} CSV files\")\n","\n","  # Read and concatenate csv files\n","  dataframe = [pd.read_csv(os.path.join(csv_dir, file)) for file in csv_files]\n","  df = pd.concat(dataframe, ignore_index=True)\n","\n","  return df"],"metadata":{"id":"qIUNk9B22WxK","executionInfo":{"status":"ok","timestamp":1761482250362,"user_tz":-480,"elapsed":133,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def preprocess_bathymetry(df):\n","    \"\"\"\n","    Preprocess bathymetry data by removing null depth values and adding spectral indices.\n","\n","    Parameters:\n","    df (pd.DataFrame): Input dataframe with satellite bands and depth values\n","\n","    Returns:\n","    pd.DataFrame: Preprocessed dataframe with spectral indices\n","    \"\"\"\n","\n","    print(f\"\\n{'='*70}\")\n","    print(\"REMOVING NULL DEPTH VALUES\")\n","    print(f\"{'='*70}\")\n","\n","    initial_count = len(df)\n","    merged_df = df.dropna(axis=0, subset=['depth']).copy()\n","    removed_count = initial_count - len(merged_df)\n","\n","    print(f\"Removed {removed_count} rows with null depth values\")\n","    print(f\"Remaining samples: {len(merged_df)}\")\n","\n","    return merged_df"],"metadata":{"id":"tvNUHO-3shpN","executionInfo":{"status":"ok","timestamp":1761485152782,"user_tz":-480,"elapsed":17,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["def preprocess_bathymetry(df):\n","    \"\"\"\n","    Preprocess bathymetry data by removing null depth values and adding spectral indices.\n","\n","    Parameters:\n","    df (pd.DataFrame): Input dataframe with satellite bands and depth values\n","\n","    Returns:\n","    pd.DataFrame: Preprocessed dataframe with spectral indices\n","    \"\"\"\n","\n","    print(f\"\\n{'='*70}\")\n","    print(\"REMOVING NULL DEPTH VALUES\")\n","    print(f\"{'='*70}\")\n","\n","    initial_count = len(df)\n","    merged_df = df.dropna(axis=0, subset=['depth']).copy()\n","    removed_count = initial_count - len(merged_df)\n","\n","    print(f\"Removed {removed_count} rows with null depth values\")\n","    print(f\"Remaining samples: {len(merged_df)}\")\n","\n","    print(f\"\\n{'='*70}\")\n","    print(\"ADDING SPECTRAL INDICES\")\n","    print(f\"{'='*70}\")\n","\n","    # Enhanced spectral indices for bathymetry and water quality\n","    try:\n","        # 1. Standard Vegetation Indices\n","        merged_df['NDVI'] = (merged_df['B8'] - merged_df['B4']) / (merged_df['B8'] + merged_df['B4'])\n","        merged_df['NDWI'] = (merged_df['B3'] - merged_df['B8']) / (merged_df['B3'] + merged_df['B8'])\n","        merged_df['SAVI'] = (merged_df['B8'] - merged_df['B4']) / (merged_df['B8'] + merged_df['B4'] + 0.5) * 1.5\n","\n","        # 2. Water-specific indices for bathymetry\n","        # Modified Normalized Difference Water Index (MNDWI)\n","        merged_df['MNDWI'] = (merged_df['B3'] - merged_df['B11']) / (merged_df['B3'] + merged_df['B11'])\n","\n","        # Water Ratio Index\n","        merged_df['WRI'] = (merged_df['B3'] + merged_df['B4']) / (merged_df['B8'] + merged_df['B11'])\n","\n","        # 4. Turbidity and water quality indices\n","        # Normalized Difference Turbidity Index\n","        merged_df['NDTI'] = (merged_df['B4'] - merged_df['B3']) / (merged_df['B4'] + merged_df['B3'])\n","\n","        # Suspended Particulate Matter Index\n","        merged_df['SPMI'] = merged_df['B4'] / (merged_df['B2'] + 1e-9)\n","\n","        # 5. Additional useful indices\n","        # Brightness Index (useful for shallow water detection)\n","        merged_df['BI'] = (merged_df['B2'] + merged_df['B3'] + merged_df['B4']) / 3\n","\n","\n","        print(\"Successfully added 10 spectral indices:\")\n","        indices_list = ['NDVI', 'NDWI', 'SAVI', 'MNDWI', 'WRI', 'NDTI', 'SPMI', 'BI']\n","        for idx in indices_list:\n","            if idx in merged_df.columns:\n","                print(f\"  âœ“ {idx}\")\n","\n","        # Check for infinite values and replace with NaN\n","        inf_count = np.isinf(merged_df[indices_list]).sum().sum()\n","        if inf_count > 0:\n","            print(f\"Replacing {inf_count} infinite values with NaN\")\n","            merged_df = merged_df.replace([np.inf, -np.inf], np.nan)\n","\n","    except KeyError as e:\n","        print(f\"Error: Missing required band {e}\")\n","        print(\"Available columns:\", df.columns.tolist())\n","        return None\n","    except Exception as e:\n","        print(f\"Error calculating spectral indices: {e}\")\n","        return None\n","\n","    print(f\"\\n{'='*70}\")\n","    print(\"DATA QUALITY CHECK\")\n","    print(f\"{'='*70}\")\n","\n","    # Data quality information\n","    print(f\"Final dataset shape: {merged_df.shape}\")\n","    print(f\"Null values in depth: {merged_df['depth'].isnull().sum()}\")\n","\n","    # Check spectral indices for extreme values\n","    spectral_cols = [col for col in merged_df.columns if col not in df.columns]\n","    if spectral_cols:\n","        print(f\"\\nSpectral indices value ranges:\")\n","        for col in spectral_cols:\n","            if col in merged_df.columns:\n","                valid_data = merged_df[col].replace([np.inf, -np.inf], np.nan).dropna()\n","                if len(valid_data) > 0:\n","                    print(f\"  {col}: [{valid_data.min():.3f}, {valid_data.max():.3f}]\")\n","\n","    return merged_df"],"metadata":{"id":"6zU9pwqBb59I","executionInfo":{"status":"ok","timestamp":1761482456552,"user_tz":-480,"elapsed":72,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def print_df(df, name=\"DataFrame\", max_rows=20, max_cols=None, show_info=True):\n","    \"\"\"\n","    Print DataFrame in a nicely formatted way.\n","\n","    Parameters:\n","    df (pd.DataFrame): DataFrame to print\n","    name (str): Name to display for the DataFrame\n","    max_rows (int): Maximum number of rows to display\n","    max_cols (int): Maximum number of columns to display\n","    show_info (bool): Whether to show DataFrame info\n","    \"\"\"\n","\n","    print(f\"\\n{'='*80}\")\n","    print(f\"ðŸ“Š {name.upper()}\")\n","    print(f\"{'='*80}\")\n","\n","    if show_info:\n","        print(f\"Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n","        print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n","        print(f\"Columns: {list(df.columns)}\")\n","\n","    print(f\"\\n{'â”€'*80}\")\n","    print(\"DATA PREVIEW:\")\n","    print(f\"{'â”€'*80}\")\n","\n","    # Set display options for better formatting\n","    with pd.option_context(\n","        'display.max_rows', max_rows,\n","        'display.max_columns', max_cols,\n","        'display.width', 120,\n","        'display.float_format', '{:.4f}'.format,\n","        'display.colheader_justify', 'center'\n","    ):\n","        print(df)\n","\n","    print(f\"{'-'*80}\")"],"metadata":{"id":"kef9Tx-UmlBU","executionInfo":{"status":"ok","timestamp":1761483630117,"user_tz":-480,"elapsed":19,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","\n","  dir = '/content/drive/MyDrive/Bathymetry/ECHOSOUNDER/bathymetry'\n","\n","  bathy = read_csv(dir)\n","  bathy_processed = preprocess_bathymetry(bathy)\n","\n","  print(bathy_processed)\n","  #print_df(bathy_processed, max_rows=10, max_cols=10)\n","\n","  print(f\"\\n{'='*80}\")\n","  print(f\"SAVE CSV FILE\")\n","  print(f\"{'='*80}\")\n","\n","  out_dir = '/content/drive/MyDrive/Bathymetry/ECHOSOUNDER'\n","  print(\"saving csv file to \", out_dir)\n","  bathy_processed.to_csv(os.path.join(out_dir, 'bathymetry_processed.csv'), index=False)\n","\n","  print(\"done ...\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqzqeQUEa4hO","executionInfo":{"status":"ok","timestamp":1761485578790,"user_tz":-480,"elapsed":952,"user":{"displayName":"Christian Candido","userId":"04121477428710958590"}},"outputId":"8e5cdfb4-8655-4b6f-9e48-818bccee454e"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","READ AND PROCESS CSV FILES\n","======================================================================\n","Found 7 CSV files\n","\n","======================================================================\n","REMOVING NULL DEPTH VALUES\n","======================================================================\n","Removed 7162 rows with null depth values\n","Remaining samples: 49189\n","          id        lat         lon  depth  wtemp      B1        B2        B3  \\\n","0          0  15.514707  119.902056   0.45  31.32  0.0368  0.029180  0.046980   \n","1          1  15.514716  119.902062   0.85  31.32  0.0333  0.027885  0.043235   \n","2          2  15.514760  119.902070   0.78  31.32  0.0333  0.027885  0.043235   \n","3          3  15.514773  119.902070   0.45  31.31  0.0333  0.027885  0.043235   \n","4          4  15.514788  119.902071   0.76  31.31  0.0333  0.027885  0.043235   \n","...      ...        ...         ...    ...    ...     ...       ...       ...   \n","56136  24020  13.916629  120.616781   1.16  31.09  0.0493  0.045670  0.057270   \n","56137  24021  13.916625  120.616786   1.16  31.08  0.0493  0.045670  0.057270   \n","56138  24022  13.916617  120.616798   1.16  31.08  0.0493  0.045670  0.057270   \n","56139  24023  13.916609  120.616813   1.16  31.08  0.0493  0.045670  0.057270   \n","56140  24024  13.916606  120.616821   1.16  31.07  0.0493  0.045670  0.057270   \n","\n","             B4       B8      B8A     B11      B12  \n","0      0.026680  0.01480  0.01090  0.0070  0.00950  \n","1      0.026635  0.01585  0.01035  0.0067  0.00875  \n","2      0.026635  0.01585  0.01035  0.0067  0.00875  \n","3      0.026635  0.01585  0.01035  0.0067  0.00875  \n","4      0.026635  0.01585  0.01035  0.0067  0.00875  \n","...         ...      ...      ...     ...      ...  \n","56136  0.037770  0.01370  0.01360  0.0153  0.01350  \n","56137  0.037770  0.01370  0.01360  0.0153  0.01350  \n","56138  0.037770  0.01370  0.01360  0.0153  0.01350  \n","56139  0.037770  0.01370  0.01360  0.0153  0.01350  \n","56140  0.037770  0.01370  0.01360  0.0153  0.01350  \n","\n","[49189 rows x 13 columns]\n","\n","================================================================================\n","SAVE CSV FILE\n","================================================================================\n","saving csv file to  /content/drive/MyDrive/Bathymetry/ECHOSOUNDER\n","done ...\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"SKSNVNvVbiQa"},"execution_count":null,"outputs":[]}]}